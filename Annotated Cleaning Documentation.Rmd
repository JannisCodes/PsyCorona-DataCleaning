---
title: "Psycorona - Data Cleaning Documentation"
subtitle: "Step by step description" 
author: "PsyCorona Gang"
date: "3/30/2020"
output:
  html_document: 
    code_folding: hide
    mathjax: default
    theme: yeti
    toc: yes
    toc_float: yes
editor_options:
  chunk_output_type: console
---


<style type="text/css">
.main-container {
  max-width: 1300px;
  margin-left: auto;
  margin-right: auto;
}
.table {
  margin-left:auto; 
  margin-right:auto;
}
</style>


```{r setup, include=FALSE}
# R Studio Clean-Up
  cat("\014") # clear console
  rm(list=ls()) # clear workspace
  gc # garbage collector
  
# Install and Load Packages
  #if(!require(pacman)) install.packages("pacman")
  # require(pacman)
  # pacman::p_load(psych, ggplot2, ggthemes, haven, data.table, dplyr, tidyr, Hmisc, mada, 
  #                knitr, kableExtra, naniar, stats, readxl, matrixStats, ISOcodes, pander,
  #                Scale)
lib <- c("psych", "ggplot2", "ggthemes", "haven", "data.table", "dplyr", "tidyr", "Hmisc", "mada", 
         "knitr", "kableExtra", "naniar", "stats", "readxl", "matrixStats", "ISOcodes", "pander", "Scale")

invisible(lapply(lib, library, character.only = TRUE))  
lapply(lib, library, character.only = TRUE)
rm(lib)  

# Load Custom Packages  
  source("./scripts/functions/fun.panel.R")
  source("./scripts/functions/themes.R")
  source("./scripts/functions/dictionary_functions.R")
  
# Markdown Options
  knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # set working directory
  knitr::opts_knit$get("root.dir") # check working directory
  options(scipen = 999, digits = 4, width = 400) #removes scientific quotation
  #knitr::opts_chunk$set(echo = TRUE, cache = F, cache.path = rprojroot::find_rstudio_root_file('cache/')) # cache settings
  knitr::knit_hooks$set(
   error = function(x, options) {
     paste('\n\n<div class="alert alert-danger">',
           gsub('##', '\n', gsub('^##\ Error', '**Error**', x)),
           '</div>', sep = '\n')
   },
   warning = function(x, options) {
     paste('\n\n<div class="alert alert-warning">',
           gsub('##', '\n', gsub('^##\ Warning:', '**Warning**', x)),
           '</div>', sep = '\n')
   },
   message = function(x, options) {
     paste('\n\n<div class="alert alert-info">',
           gsub('##', '\n', x),
           '</div>', sep = '\n')
   }
  )
  htmltools::tagList(rmarkdown::html_dependency_font_awesome())

# Global Chunk Options
  knitr::opts_chunk$set(echo = TRUE)
```

Note. Boxplots display the interquartile range (IQR, center box), and the whiskers extend 1.5*IQR from the lower and upper hinge. The white point indicates the mean and the white center line indicates the median.   

<br/>

## **Import Data**
In a first step we import the raw Qualtrics data, which was downloaded as an SPSS file.   
### Baseline
```{r LoadRawBase, echo=T, warning=F, message=F}
# Reset working directory to folder current file is saved in
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# Import Qualtrics Survey Data
dt0RawRUG <- read_spss("data/raw data/Snowball+Corona+Long-Term+Coverage+-+Baseline_April+2,+2020_08.59.sav")
dt0RawRUG$source <- "RUG"

dt0RawNYUAD <- read_spss("data/raw data/Snowball Corona Long-Term Coverage - Baseline - Copy_April 14, 2020_03.00.sav")
dt0RawNYUAD$source <- "NYU-AD"

# prepare dfs before merge (basically naming variables correct)
notRug <- dt0RawRUG %>%
  dplyr::select_if(!(names(dt0RawRUG) %in% names(dt0RawNYUAD)))
notNyu <- dt0RawNYUAD %>%
  dplyr::select_if(!(names(dt0RawNYUAD) %in% names(dt0RawRUG)))
names(notRug)
names(notNyu)
cat("Looks good as non-overlapping variables pertain to the political items"); rm(notRug, notNyu)

# merge adn fill missing
dt0Raw <- plyr::rbind.fill(dt0RawRUG, dt0RawNYUAD)

rm(dt0RawRUG, dt0RawNYUAD)
```

The raw data set includes `r length(dt0Raw)` variables for `r nrow(dt0Raw)` cases.   

### Recontacts
```{r LoadRawRec, echo=T, warning=F, message=F}
# Import Wave 1
  dt0w1 <- read_spss("data/raw data/Snowball+Corona+Long-Term+Coverage+-+Wave+2_April+13,+2020_19.07.sav")
  #dt0w2 <- read_spss("data/raw data/Snowball+Corona+Long-Term+Coverage+-+Wave+2_April+13,+2020_19.07.sav")

# prepare dfs before merge (basically naming variables correct)
notBase <- dt0Raw %>%
  dplyr::select_if(!(names(dt0Raw) %in% names(dt0w1)))
notRec <- dt0w1 %>%
  dplyr::select_if(!(names(dt0w1) %in% names(dt0Raw)))
names(notBase)
names(notRec)
cat("Needs fixing so that item names correspond to same construct"); rm(notBase, notRec)

# change column names for waves
  colnames(dt0w1) <- paste("w1", colnames(dt0w1), sep = "_")
  #colnames(dt0w2) <- paste(colnames(dt0w1), "w2",  sep = "_")

# create correct ID for merge across waves
  dt0Raw$mergeID <- as.character(dt0Raw$ResponseId)
  dt0w1$mergeID <- as.character(dt0w1$w1_ExternalReference)
  #dt0w2$mergeID <- dt0w1$ExternalReference_w2
  
# merge
  dt0Raw <- list(dt0w1, dt0Raw) %>% #merge multiple dfs at once
    Reduce(function(dtf1,dtf2) dplyr::right_join(dtf1,dtf2,by="mergeID"), .)

# find mistakes if not the same length
cat("How many people did we loose in wave 1:")
  nrow(dt0w1) - sum(dt0Raw$ICRec_1_TEXT == dt0Raw$w1_RecipientEmail, na.rm = T)
cat("We lost them because an independent link was sent around")

rm(dt0w1)
```

## **Data Quality**   

### Filter: Preview Responses
Filter the Preview responses.
```{r preview, echo=T, warning=F, message=F}
# flag Preview Responses
dt1Preview <- dt0Raw %>%
  mutate(FilterPreview = labelled(ifelse(Status == 0,0,1),
                                  labels = c(preview = 1), label="Filter: survey preview response"))
```


### Filter: Survey Progress (drop out)  
<!-- https://cran.r-project.org/web/packages/naniar/vignettes/naniar-visualisation.html -->

Inspecting missing data in the items.

```{r Missing, echo=T, warning=F, message=F}
# Table: Missing Data per item
dt1Preview %>%
  dplyr::select(-starts_with("t_"), -starts_with("Pol")) %>% #drop timers and Political orientation (because of translation missingness)
  dplyr::select_if(~sum(is.na(.)) > 0) %>% # remove all variables that have no missingess
  naniar::miss_var_summary(.) %>% # by variable summary of missingness proportion
  DT::datatable(.,
                colnames = c("Variable", "Number Missing", "Percentage Missing"),
                filter = 'top',
                extensions = 'Buttons',
                options = list(
                  columnDefs = list(list(className = 'dt-center')),
                  #autoWidth = TRUE,
                  dom = 'Bfrtlip',
                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))) %>%
  DT::formatRound('pct_miss', digits = 2)
  
# Plot: Missing Data per item
dt1Preview %>%
  dplyr::select(-starts_with("t_"), -starts_with("Pol")) %>% #drop timers and Political orientation (because of translation missingness)
  dplyr::select_if(~sum(is.na(.)) > 0) %>% # remove all variables that have no missingess
  naniar::gg_miss_var(.) # visualize by variable summary of missingness proportion

# Plot: Missing Data cumulative
dt1Preview %>%
  dplyr::select(-starts_with("t_"), -starts_with("Pol")) %>% #drop timers and Political orientation (because of translation missingness)
  dplyr::select_if(~sum(is.na(.)) > 0) %>% # remove all variables that have no missingess
  naniar::gg_miss_var_cumsum(.) # missingness development over survey

# Co-occurences of missingess - too many variables
#dt0Raw %>%
#  dplyr::select(-starts_with("t_"), -starts_with("Pol")) %>% #drop timers and Political orientation (because of translation missingness)
#  dplyr::select_if(~sum(is.na(.)) > 0) %>% # remove all variables that have no missingess
#  naniar::gg_miss_upset(., nsets = n_var_miss(.)) # visualize missingess co-occurences

# set time cut-off criterion:
progressCutOff <- 97 #cut-off criterion in percent
progressFilter <- dt1Preview %>%
  dplyr::select(Progress) %>%
  mutate(out = Progress < progressCutOff)

progressCutOffPerc <- round(sum(progressFilter$out)/nrow(progressFilter)*100,2) # percent of missing data with current cut-off criterion

# plot histogram and missing
ggplot(data=progressFilter, aes(x=Progress, fill=out)) +
  geom_histogram(bins=50,
                 alpha=.6) +
  geom_vline(xintercept = progressCutOff, 
             color = "darkred",
             linetype = "longdash") +
  geom_text(aes(x=progressCutOff, label=paste0("Progress cut-off: ",progressCutOff,"%\n"), y=Inf), 
            hjust = 1,
            colour="darkred", 
            angle=90) +
  geom_text(aes(x=progressCutOff, label=paste0("\ndata loss: ",progressCutOffPerc,"%"), y=Inf), 
            hjust = 1,
            colour="darkred", 
            angle=90) +
  #scale_x_continuous(breaks = seq(0, 100,3)) +
  scale_fill_manual(values=c("darkgrey","darkred")) +
  labs(title = "Histogram: Survey Progress", 
       x = "Survey Progress [Percent completed]",
       y = "Frequency Count") +
  theme_Publication() +
  theme(legend.position = "none")

# flag anyone with less than 5 minutes survey duration
dt2Progress <- dt1Preview %>%
  mutate(FilterProgress = labelled(ifelse(Progress < progressCutOff,1,0),
                               labels = c(`consent` = 1), label="Filter: Did not see debriefing"))

rm(progressFilter, progressCutOff, progressCutOffPerc)
```


### Filter: Short Duration on Survey   
Filter survey responses that were shorter than 5 minutes.   
```{r Duration, echo=T, warning=F, message=F}
# truncate data:
tOutlierHigh <- dt2Progress %>%
  dplyr::select(Duration__in_seconds_) %>%
  filter(Duration__in_seconds_<=stats::median(Duration__in_seconds_)+stats::mad(Duration__in_seconds_)*3.5) %>%
  mutate(Minutes = Duration__in_seconds_/60)

# set time cut-off criterion:
tCutOff <- 5 #cut-off criterion in minutes
# CJ: This might be a bit strict, I suspect that I completed it in <10 minutes. 
tCutOffPerc <- round(sum(tOutlierHigh$Minutes<tCutOff)/nrow(dt2Progress)*100,2) # percent of missing data with current cut-off criterion
tOutlierHigh$out <- tOutlierHigh$Minutes < tCutOff

# plot histogram and missing
ggplot(data=tOutlierHigh, aes(x=Minutes, fill=out)) +
  geom_histogram(bins=round(max(tOutlierHigh$Minutes),0),
                 alpha=.6) +
  geom_vline(xintercept = tCutOff, 
             color = "darkred",
             linetype = "longdash") +
  geom_text(aes(x=tCutOff, label=paste0("time cut-off: ",tCutOff," Minutes\n"), y=Inf), 
            hjust = 1,
            colour="darkred", 
            angle=90) +
  geom_text(aes(x=tCutOff, label=paste0("\ndata loss: ",tCutOffPerc,"%"), y=Inf), 
            hjust = 1,
            colour="darkred", 
            angle=90) +
  scale_x_continuous(breaks = seq(0, round(max(tOutlierHigh$Minutes),0), 5)) +
  scale_fill_manual(values=c("darkgrey","darkred")) +
  labs(title = "Truncated Histogram: Survey Duration", 
       x = "Duration [Mintues]",
       y = "Frequency Count",
       caption = "Notes:
       (1) Truncated: all participants who took less time than Median+3.5*MAD
       (2) Each bin represents one Minute") +
  theme_Publication() +
  theme(legend.position = "none")

# flag anyone with less than 5 minutes survey duration
dt3Time <- dt2Progress %>%
  mutate(FilterTime = labelled(ifelse(Duration__in_seconds_ > tCutOff*60,0,1),
                               labels = c(`extremely quick` = 1), label="Filter: Took less than 5 minutes on survey"))


rm(tOutlierHigh, tCutOff, tCutOffPerc)
# flag anyone with less than 5 minutes survey duration
dt2Time <- dt1Preview %>%
  mutate(FilterTime = labelled(ifelse(Duration__in_seconds_ > 300,0,1),
                               labels = c(`extremely quick` = 1), label="Filter: Took less than 5 minutes on survey"))
```


### Filter: Straightliners   
Filter participants, who have straightlined on the job insecurity scale, which includes a reverse coded item. We only flag people who straightlined outside the median categories because all "neither agree nor disagree" might be meaningful response.   
```{r Straightliner, echo=T, warning=F, message=F}
# CheckMissingness pattern
naniar::gg_miss_upset(dt3Time %>%
  dplyr::select(ResponseId, jbInsec01, jbInsec02, jbInsec03) %>%
  na_if(., -99) # all -99 into <NA>
)

# isolate respondents who have straightlined outside a the median categories (b/c all "neither agree nor disagree" might be meaningful response) 
jobinsecRed <- dt3Time %>%
  dplyr::select(ResponseId, jbInsec01, jbInsec02, jbInsec03) %>%
  na_if(., -99) %>% # all -99 into <NA>
  na.omit() %>% # remove people who have missing data on one of the three items
  mutate(mean = rowMeans(dplyr::select(., c("jbInsec01", "jbInsec02", "jbInsec03"))), 
         sd = matrixStats::rowSds(as.matrix(dplyr::select(., c("jbInsec01", "jbInsec02", "jbInsec03"))))) %>% # calculate row-means and row-sds 
  filter(sd == 0, mean != 0)

# flag anyone who straightlined on job insecurity
dt4Straightliner <- dt3Time %>%
  mutate(FilterStraightliner = labelled(ifelse(!ResponseId %in% jobinsecRed$ResponseId,0,1),
                                        labels = c(straightliner = 1), label="Filter: straightliner on Job Insecurity"))
rm(jobinsecRed)
```


## **Data Preparation**   
Note: For each of the scales we do an item analysis, and combine the items to the mean- (.m), and factor scores (.fa). We also centered (.c) and standardized (.z) the mean scores. Most of these items are not labelled for SPSS yet. For centering and standardizing to be accurate, we first filter the relevant criteria.

### Recoded Items   
Re-coding reverse coded items and the Qualtrics language codes.
```{r recode, echo=T, warning=F, message=F}
# Recoded Items
dt5newVars <- dt4Straightliner %>%
  mutate(jbInsec02_R = labelled(recode(as.numeric(jbInsec02), `-2` = 2, `-1` = 1, `0` = 0, `1` = -1, `2` = -2, `-99` = -99),
                                labels = NULL, label="Job Insecurity 02 (re-coded)"),
         disc03_R = labelled(recode(as.numeric(disc03), `-2` = 2, `-1` = 1, `0` = 0, `1` = -1, `2` = -2),
                            labels = NULL, label="Discontent 03 (re-coded)"),
         bor03_R = labelled(recode(as.numeric(bor03), `-2` = 2, `-1` = 1, `0` = 0, `1` = -1, `2` = -2),
                            labels = NULL, label="Boredom 03 (re-coded)"))
# Language
# Import Qualtrics Language Codes
qualtricsLanguage <- read_excel("data/raw data/qualtricsLanguageCodes.xlsx")
dt5newVars <- merge(x=dt5newVars, y=qualtricsLanguage, by="Q_Language", all.x=TRUE)
rm(qualtricsLanguage)
```

### Filter Participants
```{r filtBefCalc, echo=T, warning=F, message=F}
dt5newVars <- dt5newVars %>%
  filter(FilterPreview == 0,
         FilterProgress == 0,
         FilterTime == 0,
         FilterStraightliner == 0)

# TO DO: REMOVE TESTS (OFTEN STRING)
```

### Country
We currently have `r length(table(dt5newVars$country))` different free text country responses. Here we aim to consolidate them into one variable.
```{r Country, echo=T, warning=F, message=F}
# CJ: Just as a benchmark, geolocate IP address. Can always use this if a free 
# CJ: text country response does not resolve 
# MA: should only be used for those that agree; also VPNs are problematic
# library(rgeolocate)
# file <- system.file("extdata","GeoLite2-Country.mmdb", package = "rgeolocate")
# geolocations <- maxmind(dt5newVars$IPAddress, file, c("continent_name", "country_code", "country_name"))
# dt5newVars$coded_country_ip <- geolocations$country_name
# rm(geolocations)

# CJ: This is a slightly cleaner, faster, and more informative regex based approach.
# CJ: The function and dictionary (based on the code below, some errors corrected) 
# CJ: is in

#saveRDS(dt5newVars$country, file = "country.RDS")

dt5newVars$countryAdj <- dt5newVars$country %>%
  tolower() %>% #make them lower case
  gsub(" ", "", ., fixed = TRUE) %>% # remove white space
  as.character() #make sure everything is characters

source("./scripts/functions/dictionary_functions.R")

# sourcing seems to destroy everything
country_dict <- list('Afghanistan' = c('Afghanistan'),
                       'Albania' = c('albania', 'Albania'),
                       'Algeria' = c('Algrie', 'Ø§Ù„Ø¬Ø²Ø§Ø¡ Ùˆ', 'ALGERIE',  'Ø¬Ø²Ø§Ø¦Ø±',   'Alger',  'Ø§Ù„Ø¬Ø²Ø§Ø¡ Ùˆ ', 'Ø§Ù„Ø¬Ø²Ø§ÙŠØ±',  'ðŸ‡©ðŸ‡¿', 'ALGÃ‰RIE',  'Ø§Ù„Ø¨Ù„ÙŠØ¯Ø©',  'algeri', 'Ø§Ù„Ø¬Ø²Ø§Ù‰Ø±',  'Ø§Ù„Ø¬ÙˆØ§Ø¦Ø±',    'Algeria', 'Ø§Ù„Ø­Ø²Ø§Ø¦Ø±',  'Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±', 'algÃ©rie', 'Ø§Ù„Ø¬Ø²Ø§Ø¡Ø±', 'AlgÃ©rie', 'Algerie'),
                       'Algeria' = c('Ø§Ù„Ø¬Ø²Ø§ÙŠØ± (Ø­Ù…Ø§Ø¯ÙŠ Ø¨ÙˆÙ…Ø±Ø¯Ø§Ø³)', 'Ø§Ù„Ø­Ø²Ø§Ø¡Ø±'),
                       'Andorra' = c('andorra', 'Andorra'),
                       'Argentina' = c('Î‘ÏÎ³ÎµÎ½Ï„Î¹Î½Î®', 'argentina', 'Argentine', 'ARGENTINA', 'Argentina', 'arge'),
                       'Australia' = c('australia', 'austrlaia',  'austrija', 'Australia'),
                       'Austria' = c('ÐÐ²ÑÑ‚Ñ€Ñ–Ñ', 'Asturies', 'austria', 'Austrija', 'Austria', 'sterreich', 'Australia'),
                       'Azerbaijan' = c('azerba', 'Azarbaycan',  'Azerbaycan', 'Azerbaijan'),
                       'Bahrain' = c('bahrain', 'Bahrain'),
                       'Bangladesh' = c('bangladesh', 'Bangladesh'),
                       'Belgium' = c('Î’ÎµÎ»Î³Î¹Î¿', 'Î²ÎµÎ»Î³Î¹Î¿', 'Belgien', 'Ð‘ÐµÐ»ÑŒÐ³Ð¸Ñ', 'BÃ©lgica', 'Î’ÎµÎ»Î³Î¹Î¿', 'Î²ÎµÎ»Î³Î¹Î¿', 'Belgica', 'Belgio', 'Belgie', 'BelgiÃ«', 'belg', 'Belgique', 'bÃ©lgica', 'Ð±ÐµÐ»ÑŒÐ³Ð¸Ñ', 	'Belgium'),
                       'Bosnia and Herzegovina' = c('Bosnia and Herzegovina', 'bosnaihercegovina', 'Bosna i Hercegovina'),
                       'Botswana' = c('botswana'),
                       'Brazil' = c('brazil', 'Rio de Janeiro', 'Esp santo', 'Brassil', 'BRASIL', 'Brazil', 'brasil', 'Brasil'),
                       'Bulgaria' = c('bulgaria', 'Bulgaria', 'Ð±ÑŠÐ»Ð³Ð°Ñ€Ð¸Ñ'),
                       'Cambodia' = c('Cambodia'),
                       'Cameroon' = c('camer', 'Cameroun'),
                       'Canada' = c('canad', 'Ú©Ø§Ù†Ø§Ø¯Ø§', 'Windsor', 'QuÃ©bec', 'Ontario', 'Vancouver', 'vancouver', 'ÐšÐÐÐÐ”Ð', 'CANADA', 'CanadÃ¡', 'ÐšÐ°Ð½Ð°Ð´Ð°',  'ÐºÐ°Ð½Ð°Ð´Ð°', 'Canada'),
                       'Chile' = c('^chile$', 'CHile',  'Chile', 'CHILE'),
                       'China' = c('^china','Macao', 'Macau',  'Hui', 'Chine', 'å±±ä¸œæ³°å®‰ä¸œå¹³åŽ¿', 'ä¸­å›½', 'ä¸­åŽäººæ°‘å…±å’Œå›½', 'China', 'ä¸­åœ‹'),
                       'Colombia' = c('colombia', 'Colombia', 'COLOMBIA'),
                       'Costa Rica' = c('costa', 'Costa rica', 	'Costa Rica'), 
                       'Croatia' = c('croa', 'Kroatien', 'HorvÃ¡torszÃ¡g',  'CroÃ¡cia', 'Croazia',  'HRVATSKA', 'Hrvatskoj', 'Hrv', 	'Hrvarska', 'Hrvatska', "hrvatsk", 'Croatia'),
                       'Cyprus' = c('ÎšÏÏ€ÏÎ¿Ï‚', 'ÎšÏ…Ï€ÏÎ¿', 'ÎšÏÏ€ÏÎ¿', 'Cypris', 'cyp', 'ÎšÏ…Ï€ÏÎ¿','Kuzey KÄ±brÄ±s TÃ¼rk Cumhuriyeti',  'Kuzey KÄ±brÄ±s TÃ¼rk Cumhuriyeti', 'ÎšÏ…Ï€ÏÎ¿Ï‚', 'ÎšÏÏ€ÏÎ¿Ï‚', 'ÎšÏÏ€ÏÎ¿Ï‚', '^Îº...Î¿.', '^Îº...Î¿', 'Cyprus'), 
                       'Czech Republic' = c('czech', 'Î¤ÏƒÎµÏ‡Î¯Î±', 'Republica Checa', 'ÄeÅ¡ka republika', 'Tschechien',  'RepÃºblica Checa',  'Czechia',  'Czech Republic', 'checa'),
                       'Denmark' = c('mark'), 
                       'Dominican Republic' = c('domin', 'Dominican Republic', 'RepÃºblica Dominicana'),
                       'Ecuador' = c('ecuador', 'Quito', 'Ecuador'),
                       'Egypt' = c('Ù…ØµØ±', 'Egypt'),
                       'El Salvador' = c('salvador', 'El salvado', 'El Salvaodr', 'El Salvador'),
                       'Estonia' = c('estonia', 'Estonia'),
                       'Finland' = c('finland', 'Finnland', 'Finland'),
                       'France' = c('france', 'VendÃ©e', 'Valmontone (RM)', 'vouziers', 'RÃ©gion PACA', 'Paris', 'ParÃ­s', 'Oise', 'nouvelle-calÃ©donie', 'LYON', 'Guyane FranÃ§aise', 'Guadeloupe', 'Grand est', 'Fransa', 'Frznce', 'RÃ©union', 'Franche', 'Frankreich', 'FranÃ§a',  'Frankrijk', '^fr$', 'La RÃ©union', 'La rÃ©union', 'Francia', 'France', 'FRANCE', 'francia',  'frankrijk'),
                       'Gabon' = c('Gabon'),
                       'Germany' = c('Duitsland', 'NÃ©metorszÃ¡g', 'NemaÄka', 'Nemacka', 'Germanis', 'Î“Î•Î¡ÎœÎ‘ÎÎ™Î‘', 'Ø¢Ù„Ù…Ø§Ù†', 'Ð“ÐµÑ€Ð¼Ð°Ð½Ð¸Ñ', 'Ø£Ù„Ù…Ø§Ù†ÙŠØ§', 'Berlin', 'Î“ÎµÏÎ¼Î±Î½Î¹Î±', 'Allemagne', 'germany', 'Î“ÎµÏÎ¼Î±Î½Î¯Î±', 'Î“ÎµÏÎ¼Î±Î½Î¯Î±', 'Almanya', 'Alemania', 'Germania',  'Germany', 'Deutschland', 'deutschland',  'alemania',  'germania',  '^almanya$', 'allemagne',  'berlin',  'duitsland', 'Î³.Ï.....'),
                       'Greece' = c('Î•Î›Î›Î‘Î£Î‘', 'Î•Î»Î»Î±', 'Î™Ï‰Î¬Î½Î½Î¹Î½Î±', 'greece', 'Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ·', 'Hellas', 'GRecia', 'Griechenland', 'Griekenland',  'GrÃ¨ce',  'Ellada', 'å¸Œè…Š', 'GRECE', 'ellada', 'Grecia', 'GREECE', 'Î•Î»Î»Î±', 'Î•Î›Î›Î‘Î£', 'Î•Î›Î›Î‘Î£Î‘', 'Î•Î›Î›Î†Î”Î‘', 'Greece', 'Î•Î›Î›Î‘Î”Î‘', 'grecia', 	'.Î»Î»...', '.Î»Î»..', 'ÎµÎ»Î»Î¬Î´Î±'),
                       'Guatemala' = c('guat', 'Guatemala'),
                       'Hong Kong S.A.R.' = c('Hongkong', 'Hk', 'HK', 'HONG KONG', 'HongKong', 'Hong kong',  'hong.{0,}kong', 'é¦™æ¸¯', 'Hong Kong'),
                       'Hungary' = c('Hungary', 'Ungheria', 'Ungarn', 'MaÄ‘arska', 'hungary', 'Magyar', 'Magyarorszag', 'MagyaroszÃ¡g', 'MagyarorszÃ¡g', '^magyarorsz', 'magyar', 'ungarn'),
                       'Iceland' = c('iceland', 'Iceland'),
                       'India' = c('india', 'Ù‡Ù†Ø¯', 'Imdia', 'INDIA', 'Infis',  'India'),
                       'Indonesia' = c('Jakarta', 'Indomesia', 'Insonesia', 'IndÃ²nesia', 'Yogyakarta, indonesia', 'IndonesiÃ ', 'Indonedia', 'Indomesia	', 'Indoesia', 'Indobesia', 'Imdonesia', 'Indoasia', 'indo', 'INdonesia', 'INDONESIA', '^indonesia$', 'Indonesia', 'indonesian',  'kota, tarakan',  'imdonesia',  'indÃ²nesia',  'jakarta'),
                       'Iran' = c('iran', 'Ø§ÛŒØ±Ø§Ù†', 'Iran'),
                       'Iraq' = c('Ø¹Ø±Ø§Ù‚',  'iraq', 'Ø§Ù„ØºØ±Ø§Ù‚', 'Iraq', 'Ø§Ù„Ø¹Ø±Ø§Ù‚'),
                       'Ireland' = c('Î™ÏÎ»Î±Î½Î´Î¯Î±', 'Î™ÏÎ»Î±Î½Î´Î¹Î±', '^ireland$', 'Irska', 'Ireland', 'Irlanda', 'irlanda', 'Î¹ÏÎ».....'),
                       'Israel' = c('Ø¹Ø§Ø±Ø©',   'Ø³Ø®Ù†ÙŠÙ†',   'Ø±Ù…Ù„Ù‡',   'Ø§Ù„Ù‚Ø¯Ø³','Isreal', 'Ø§Ù„Ø·ÙŠØ¨Ø©',  'Ð˜Ð·Ñ€Ð°Ð¸Ð»ÑŒ', 'Ø§Ù„Ø·ÙŠØ¨Ù‡',  'Jerusalem', 'ÙƒÙØ± Ù‚Ø§Ø³Ù…',  'Ø§Ù„Ø·ÙŠØ±Ø©', 'ISRAEL', 'Ø¬Øª Ø§Ù„Ù…Ø«Ù„Ø«', 'Israel', 'Ø¬Ù„Ø¬ÙˆÙ„ÙŠØ©',  'israel', 'Ø§Ù„Ù„Ø¯',  'Ø§Ø³Ø±Ø§Ø¦ÙŠÙ„',  'ÙƒÙØ±, Ù‚Ø§Ø³Ù…',  'isreal',  '×¨×ž×œ×”', 'Ø§Ù„Ø±Ù…Ù„Ù‡'), 
                       'Italy' = c('Ð†Ñ‚Ð°Ð»Ñ–Ñ', 'Î™Ï„Î±Î»Î¯Î±', 'Terralba', 'Tezze di Piave (Tv) ITA', 'Vicenza', 'Vergato', 'Vittorio Veneto',  'SETTIMO VITTONE', 'SS. Cosma e Damiano', 'Segni (RM)', 'Scalea', 'Scauri', 'ROMA', 'Predazzo (Tn)', 'Pellizzano', 'Padova', 'Olevano romano',  'Orosei', 'Italua', 'Itaia', 'Imola', 'Ladispoli', 'Guidonia', 'Guidonia Montecelio', 'Ferentino', 'Fiano romano', 'Chieti', 'Cala gonone',  'Brescia',  'Bari',  'Ð˜Ñ‚Ð°Ð»Ð¸Ñ',   'Ä°talya', 'Mareno di Piave', 'Frosinone', 'Italia', 'Milano', 'Dorgali', 'Castelforte', 'Bisceglie',  'Italie', 'ItaliÃ«', 'Itali', 'Italien', 'Sardegna',  'ITALIA', 'ital', 'Roma', 'Italy', 'sardegna',  'bisceglie',  'ladispoli',  'castelforte',  'milano',  '^roma$', 'dorgali',  'bari',  'bologna',  'brescia',  'cala, gonone',  'chieti',  'ferentino',  'frosinone',  'gragnano, lucca, ',  'guidonia',  'itaia',  'italya',  'mareno, di, piave',  'modena',  'pellizzano',  'predazzo',  'refrontolo',  'cosma, e, damiano',  'scalea',  'scauri',  'segni',  'settimo, vittone',  'susegana',  'terralba',  'trento',  'treviso',  'tezze, di, piave',  'valmontone',  'vergato',  'veneto',  'gragnano, lucca'),
                       'Jamaica' = c('jamaica', 'Jamaica'),
                       'Japan' = c('japan', 'JapÃ£o', 'Japonya', 'ã«ã»ã‚“', 'japon', 'Giappone',  'giappone', 'Japan', 'japonya', 'æ—¥æœ¬'),
                       'Jordan' = c(  'Ø§Ù„Ø§Ø±Ø¯Ù†', 'Jordan',   'Jordanie',  'jordan', 'Ø§Ù„Ø£Ø±Ø¯Ù†'),
                       'Kazakhstan' = c('ÐºÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½', 'Qazaqstan', 'Kazahstan', 'Kazakhstan', 'kazakhstan', 'ÐšÐ°Ð·Ð°Ñ…ÑÑ‚Ð°Ð½'),
                       'Kenya' = c('kenia', 'Kenia'),
                       'Kuwait' = c('Ø§Ù„ÙƒÙˆÙŠØª'),
                       'Laos' = c('laos', 'Laos'),
                       'Latvia' = c('latvia', 'Latvia'),
                       'Lebanon' = c('lebanon', 'LIBAN', 'Ð›Ð¸Ð²Ð°Ð½',  'Ù„Ø¨Ù†Ø§Ù†',  'Lebanon', 'liban'),
                       'Libya' = c('Ù„ÙŠØ¨ÙŠØ§'),
                       'Luxembourg' = c('lux','Luksemburg',  'Luxembourg', 'Luxemburg'),
                       'Malaysia' = c('malay', 'Malaysia', 'Ù…Ø§Ù„ÙŠØ²ÙŠØ§'),
                       'Mali' = c('Mali'),
                       'Malta' = c('malta', 'Malta'),
                       'Mauritius' = c('maurice', 'Ä°le Maurice', 'Mauritius'),
                       'Mexico' = c('mexico', 'ÎœÎµÎ¾Î¹ÎºÏŒ', 'MÃ‰XICO', 'MÃ©xico', 'mÃ©xico', 'Mexico'),
                       'Moldova' = c('Moldova'),
                       'Mongolia' = c('Mongolia'),
                       'Montenegro' = c('crnagora', 'Montenegro', 'Crna Gora'),
                       'Morocco' = c('Ø§Ù„Ù…ØºØ±Ø¨',  'rabat', 'Ø§Ù„Ù†ØºØ±Ø¨',  'MAROC', 'Ù…ØºØ±Ø¨',  'Morocco', 'Morroco', 'Maroko', 'Marruecos', 'maroc', 'Maroc'),
                       'Myanmar' = c('myanmar'),
                       'Namibia' = c('Namibia'),
                       'Nepal' = c('nepal', 'Nepal'),
                       'Netherlands' = c('Netherland','Nizozemska',  'Holandija',  'Gelderland', 'è·å…°', 'ÐÐ¸Ð´ÐµÑ€Ð»Ð°Ð½Ð´Ñ‹',  'Ð“Ð¾Ð»Ð°Ð½Ð´Ñ–Ñ', 'Paises Bajos', 'Curacao',  'Hollanda', 'PaÃ­ses Bajos', 'Paesi Bassi', 'netherland', 'Nl', 'Belanda', 'Olanda', 'New Zealand', 'NL', 'Niederlande', 'The Netherlands', 'Netherlands', 'Nederland',  'nederland',  'niederlande',  'belanda',  '^nl$',  'olanda',  'paesi, bassi',  'paesi bassi',  'bajos',  'gelderland',  'hollanda', 'paes.+bass.'),
                       'New Zealand' = c('new.+zeal',  'newzealand',  'neuseeland'),
                       'Nigeria' = c('nigeria', 'Nigeria'),
                       'North Macedonia' = c('North Macedonia'),
                       'Norway' = c('norway', 'Norway', 'NorvÃ¨ge', 'NorvÃ©ge', 'Norwegen'),
                       'Oman' = c('^oman$', 'Oman'),
                       'Pakistan' = c('pakistan', 'Ù¾Ø§Ú©Ø³ØªØ§Ù†', 'Peshawar',  'Abbottabad', 'Pak',	'Pakistan',  'abbottabad',  'peshawar'),
                       'Palestine' = c('Ù†Ø§Ø¨Ù„Ø³',     'ÙƒÙØ± Ø¹Ù‚Ø¨',     'ÙÙ„Ø³Ø·ÙŠÙ†ØŒØºØ²Ø©',     'ÙÙ„Ø³Ø·ÙŠÙ† ØºØ²Ø©',   'ÙÙ„Ø³ØªÙŠÙ†',    'ØºØ²Ø©',  'Ø±Ø§Ù…Ø§Ù„Ù„Ù‡',     '	Ø¬Ù†ÙŠÙ† - ÙÙ„Ø³Ø·ÙŠÙ†',   'Ø¨ÙŠØª Ù„Ø­Ù…', 'palestine', 'Ø±Ø§Ù… Ø§Ù„Ù„Ù‡',  'Palestine', 'ÙÙ„Ø³Ø·ÙŠÙ†, ',  '^ÙÙ„Ø³Ø·ÙŠÙ†$',  'Ø§Ù„Ø±Ù…Ù„Ø©'),
                       'Panama' = c('panam'), 
                       'Peru' = c('PERÃš', 'Peru', 'PerÃº', 'peru', 'perÃº'),
                       'Philippines' = c('Phillipines', 'Ph', 'Pilipinas', 'Phil', 'Philippinea', 'phil',  'filipinas', 'Philippines', 'PHILIPPINES'),
                       'Poland' = c('poland', 'POLAND', 'POLONIA', 'Portogallo', 'Poland',  'polonia', 'ÐŸÐ¾Ð»ÑŒÑˆÐ°', 'Ð¿Ð¾Ð»ÑŒÑˆÐ°'),
                       'Portugal' = c('portugal', 'è‘¡è„ç‰™', 'Portugal'), 
                       'Qatar' = c('qatar', 'Qatar', 'Katar'),
                       'Romania' = c('romania', 'ROMANIA', 'Roumanie',  'Romania', 'RomÃ¢nia', 'rom.nia'),
                       'Russia' = c('Ñ€Ð¾ÑÑÐ¸Ñ', 'Ð Ð¾ÑÑÐ¸Ñ', 'Rusia'),
                       'Republic of Belarus' = c('Belarus'),
                       'Republic of Kosovo' = c('Kosovo'),
                       'Republic of Chad' = c('Tchad'),
                       'Republic of Serbia' = c('srbija', 'Serbis', 'ServiÃ«', 'SEBIA', 'Ð£ Ð¡Ñ€Ð±Ð¸Ñ˜Ð¸',  'Ñƒ Ð¡Ñ€Ð±Ð¸Ñ˜Ð¸',  'Ð¡Ñ€Ð±Ð¸Ñ˜Ñ', 'Szerbia', 'Srpski', 'Srbiji', 'SRBIJA',  'serbia',  'ÑÑ€Ð±Ð¸Ñ˜Ð°', 'Serbia','srbiji', 'Ð¡Ñ€Ð±Ð¸Ñ˜Ð°', 's.erbia', 'Srbija'),
                       'Rwanda' = c('Rwanda'),
                       'Saudi Arabia' = c('Ø§Ø±ÙŠØ§',  'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø© Ø§Ù„Ù…Ù†ÙˆØ±Ø©', 'Ø§Ù„Ù…Ù…Ù„ÙƒØ©', 'Ø¬Ø§Ø²Ø§Ù†',  'Ø¬Ø¯Ù‡',  'SaudiArabia', 'Ø¬Ø¯Ø©',  'Riyadh',  'Sa',    'Ø³Ø¹ÙˆØ¯ÙŠÙ‡',  'Riyad', 'Saudi', 'K.S.A',  'Arabia Saudita', 'Arabie saoudite', 'Saidi Arabia', '	Saudi arbia', 'Ksa', 'Saudi Arabia', 'SA', 'riyad',  'saud.+arab',  'arabia, saudita',  '^saudi$',  'kingdom, of, saudia, arabia',  'ksa',  'k\\.s\\.a',  'arabie, saoudite',  'Ø§Ù„Ø±ÙŠØ§Ø¶',  'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©',  'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‡', 'emira+arab'),
                       'Singapore' = c('singapore', 'SINGAPORE', 'Singapur', 'Singapore'),
                       'Slovakia' = c('slova', 'Ð¡Ð»Ð¾Ð²Ð°Ñ‡Ñ‡Ð¸Ð½Ð°',   'SzlovÃ¡kia',  'Slovakia', 'Slovak Republic'),
                       'Slovenia' = c('Slovenia', 'Slovenija'),
                       'South Africa' = c('Ø¬Ù†ÙˆØ¨ Ø£ÙØ±ÙŠÙ‚ÙŠØ§', 'Garankuwa','Western Cape',  'Limpopo', 'Western cape', 'Eastern Cape', 'Cape Town', 'Gauteng', 'SOUTH AFRICA', 'South aftica', 'South Afica', 'South AFRICA', 'South Africa', 'africa',  '^sa$',  'sudÃ¡frica',  'western, cape', 'southaf...'),
                       'South Korea' = c('korea', 'í•œêµ­', 'Korea, Republic of', 'GÃ¼ney Kore', 'Korea Selatan, Busan',  'South Korea', 'gÃ¼ney, kore'),
                       'Spain' = c('Ð˜ÑÐ¿Ð°Ð½Ð¸Ñ', 'Î™ÏƒÏ€Î±Î½Î¯Î±', 'Pais vasco', 'MontalbÃ¡n de CÃ³rdoba', 'Madrid', 'MÃ¡laga', 'Fuerteventura', 'EspÃ±a', 'Es', 'EsapaÃ±a', 'El RocÃ­o', 'EapaÃ±a', 'CataluÃ±a', 'Andalucia', 'Catalunya', 'EspsÃ±a', 'Euskal Herria', 'Ð†ÑÐ¿Ð°Ð½Ñ–Ñ', 'SpanyolorszÃ¡g', 'SPAIN', 'Estado EspaÃ±ol', 'EspaÃ±istan', 'ESpaÃ±a', 'Espanha', 'Espana', 'Spanje', 'EspaÃ±s', 'EspaÃ±', 'Espagne', 'Spanien', 'EspaÃ±ol', 'Espanya', 'spain', 'Spagna', 'Spain', 'esp', 'ESPAÃ‘A', 'EspaÃ±a', 'spagna',  'spanien',  'catal',  'euskal, herria',  'basque',  'eapaÃ±a',  'esapaÃ±a',  'madrid',  'montalbÃ¡n, de, cÃ³rdoba',  'pais, vasco',  'spanje'),
                       'Sweden' = c('weden','Svezia', 'SWEDEN',  'Isvec', 'SuÃ¨de'),
                       'Switzerland' = c('Î•Î»Î²ÎµÏ„Î¯Î±', 'switzerl', 'Zwitserland', 'Switzerlannd', 'Svizzera','Ä°sviÃ§re',  'Ð¨Ð²ÐµÐ¹Ñ†Ð°Ñ€Ñ–Ñ', 'Suiza', 'SUIZA', 'schweiz', 'Î•Î»Î²ÎµÏ„Î¯Î±', 'Schweiz', 'Switzerland', 'suiza', 'Suisse', 'svizzera',  'zwitserland',  'switzerland', 'suisse'),
                       'Taiwan' = c('taiwan', 'Tayvan', 'å°ç£', 'Taiwan'),
                       'Thailand' = c('^thailand$', 'Thailand'),
                       "Trinidad and Tobago" = c("trinid", 'Trinidad', 'Trinidad and Tobago'),
                       'Tunisia' = c('Tunise', 'Ø¬Ù†Ø¯ÙˆØ¨Ø©',  'Tunis', 'Tunis', 'Tunisia', 'tuni', 'Tunisie', 'ØªÙˆÙ†Ø³'),
                       'Turkey' = c('ØªØ±ÙƒÙŠØ§ - Ø§Ø³Ø·Ù†Ø¨ÙˆÙ„', 'turkey', 'ØªØ±ÙƒÙŠØ§', 'TÃ¼r', 'TÃ¼rkÃ§e', 'TÃ¼rkye', 'TÃ¼rkei', 'TÃ¼rkiy', 'Ð¢ÑƒÑ€Ñ†Ð¸Ñ',  'TÃ¼rkÄ±ye', 'Tr', 'TR', 'tr', 'TURKEY', 'Turki', 'turquie', 'TÃœRKÄ°YE', 'Turkey', 'Turkiye', 'TÃ¼rkiye', 't.rk.y.', 't.rk.{0,2}', "t[a-z]rkiye"), #"'\u00fcrkiye'"
                       'Ukraine' = c('ukraine', 'Ð£Ñ€Ð°Ñ—Ð½Ð°', 'ÐšÐ¸ÐµÐ²', 'Ð£ÐºÑ€Ñ—Ð½Ð°', 'Ð£ÐºÑ€Ð°iÐ½Ð°', 'Ð£ÐºÑ€Ð°Ñ—Ð½ÑÑŒÐºÐ°', 'Ð£ÐºÑ€Ð°Ð¸Ð½Ðµ', 'Ð£ÐšÐ ÐÐ‡ÐÐ', 'Ð£ÐºÑ€Ð°Ñ–Ð½Ð°', 'Ñƒ.Ñ€Ð°..Ð°', 'ÑƒÐºÑ€Ð°Ñ—Ð½Ð°', 'ÑƒÐºÑ€Ð°Ð¸Ð½Ð°', 'Ð£ÐºÑ€Ð°Ñ—Ð½Ð°', 'Ð£ÐºÑ€Ð°Ð¸Ð½Ð°'),
                       'United Arab Emirates' = c('U.A.E.',  'Ø§Ù„Ø¥Ù…Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„Ù…ØªØ­Ø¯Ø©' ,  'Uae' , 'Emirats Arabes Unis', 'Emiratos Arabes Unidos' ,'Abu Dhabi',  'Emiratele Arabe Unite' ,   'Dubai',   'Emirados Arabes Unidos', 'Ø§Ù„Ø®Ø±Ø¬','United Arab emirates',  'United Arab Emirates',  'UAE', 'united, arab, emirates', 'Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª', '^uae$', 'arabemirates', 'Ù„Ø¹Ø±Ø¨ÙŠØ©Ø§Ù„Ù…ØªØ­Ø¯Ø©'),
                       'United Kingdom' = c('Î‘Î³Î³Î»Î¹Î±', 'Ø§Ø³ÙƒÙˆØªÙ„Ù†Ø¯Ø§', 'Egland', 'royaume uni', 'Liverpool', 'Grand Cayman, Cayman Islands', 'GB', 'Anglia', 'Ecosse', 'Angleterre', 'Ð’ÐµÐ»Ð¸ÐºÐ¾Ð±Ñ€Ð¸Ñ‚Ð°Ð½Ð¸Ñ', 'Î‘Î³Î³Î»Î¹Î±', 'U.K','SCOTLAN', 'Schotland',  'Scozia',  'Î—Î½Ï‰Î¼Î­Î½Î¿ Î’Î±ÏƒÎ¯Î»ÎµÎ¹Î¿', 'London', 'ENGLAND', 'Verenigd Koninkrijk', 'Î‘Î³Î³Î»Î¯Î±', 'Marea Britanie', 'Britain', 'Isole Vergini Britanniche',  'Great Britain',  'United Kingdon', 'Northern ireland', 'UNITED KINGDOM', 'united Kingdom', 'Regno Unito', 'United kingdom', 'United Kingdon', 'uni.+kin', 'Wales', 'Reino Unido', 'Uk', 'Scotland', 'United Kingdom', 'England', 'UK',  '^uk$',  'reino, unido',  'britain',  'regno, unito',  'u\\.k\\.',  'Ø¨Ø±ÙŠØ·Ø§Ù†ÙŠØ§',  'the, uk',  'u, k',  'verenigd, koninkrijk',  'windsor',  'scotland',  'england',  'wales',  'ingiltere',  'northern, ireland',  'egland',  '^gb$',  'n, ireland',  'schotland',  'scozia', 'è‹±å›½', 'ngiltere', 'n.{4,9}ireland', 'reinounido', 'anglia'),
                       'United Republic of Tanzania' = c('tanzania', 'Tanzania'),
                       'United States of America' = c('ÙÙ„ÙˆØ±ÙŠØ¯Ø§',     'Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø© Ø§Ù„Ø§Ù…Ø±ÙŠÙƒÙŠØ©'  , 'Ø§Ù„ÙˆÙ„Ø§ÙŠØ§Øª Ø§Ù„Ù…ØªØ­Ø¯Ø© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©',   'Î‘Î¼ÎµÏÎ¹ÎºÎ®', 'U.s.a.', 'Tempe', 'TEXAS', 'untied states', 'TX', 'Untied STates', 'Wisconsin', 'virginia', 'illinois', 'Puerto Rico', 'Penssylvania', 'NY', 'new yark', 'Munford', 'michigan', 'midwest', 'Minnesota', 'EEUU', 'IDAHO', 'georgia', 'Amerika Serikat', 'AMERICA', 'ALASKA', '^us$', 'ë¯¸êµ­', 'Ø¢Ù…Ø±ÛŒÚ©Ø§', 'Ø£Ù…Ø±ÙŠÙƒØ§', 'Pennsylvania', 'Pennssylvania', 'United stated', 'United stares', 'Estados unidos', 'NEWYORK', 'Arizona',  'New York', 'new york', 'New york', 'NEW YORK', 'Ð¡Ð¨Ð', 'new jersey',  'Unites stats', 'California', 'Uniteed States', 'United. States','United STates','United sTATES', 'uNITED STATES', 'United Stares', 'United Staes', 'Unite States', 'ESTADOS UNIDOS', 'Unites states', 'United Ststes', 'UNited States', 'united States', 'United statea', 'United Sates', 'UNITED STATES', 'Estados Unidos', '	Estados unidos', '	ESTADOS UNIDOS', 'Untied statest', 'Unites States', 'United State', 'U.S', 'United states', 'America', 'United States', 'Usa', 'USA', 'america', '^usa', 'u.s.a',  'uni.+stat', 'uni.+merica',  '^america$',  '^u.{0,1}s.{0,1}$',  'esta.+unid',  'colorado',  'xas',  'sates',  'amerika, serikat',  'california',  'corlifornia',  'Ã©tats-unis', 'puerto, rico',  '^tx$',  '^tn$', 'ç¾Žå›½', 'new+york', 'ÑÑˆÐ°', 'un..edsta.es', 'arizona'), 
                       'Uruguay' = c('urug', 'Uruguay'),
                       'Uzbekistan' = c('u.{2,5}istan', 'Uzbekistan'),
                       'Venezuela' = c('^venezuela$', 'Venezuela'),
                       'Vietnam' = c('vietnam', 'Vietnam'),
                       'Yemen' = c('Ø§Ù„Ø¹Ù†Ø¯'),
                       
                       
                       'United States of America' = c('Ø§Ù…Ø±ÛŒÚ©Ø§'), 
                       'Saudi Arabia' = c('Ù…Ø¯ÙŠÙ†Ø© Ø¶Ø±Ù…Ø§Ø¡',      'Ø¹Ù†ÙŠØ²Ø©',    'Ø³ÙƒØ§ÙƒØ§ Ø§Ù„Ø¬ÙˆÙ',     'Ø¶Ø±Ù…Ø§Ø¡',      '	Ø³ÙƒØ§ÙƒØ§ Ø§Ù„Ø¬ÙˆÙ',  'Ø³Ø¹ÙˆØ¯ÙŠØ©',   'Ø§Ù„Ø¯Ù…Ø§Ù…', 'Ø§Ù„Ø±Ø¨Ø§Ø¶', 'Ø§Ù„Ø³Ø¹Ø±Ø¯ÙŠÙ‡', 'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠÙ‘Ù‡' ),
                       'Saudi Arabia' = c('Ø±ÙŠØ§Ø¶',  'Ø®Ø±Ø®ÙŠØ±',  'Ø­ÙØ± Ø§Ù„Ø¨Ø§Ø·Ù†',  'Ø§Ù„Ù‚ÙˆÙŠØ¹ÙŠÙ‡',   'Ø§Ù„Ù…Ø¯ÙŠÙ†Ù‡ Ø§Ù„Ù…Ù†ÙˆØ±Ø©')
      )


country_matches <- cat_words(dt5newVars$countryAdj, country_dict) 
#country_matches$words[country_matches$words %in% names(country_matches$unmatched)] <- NA
# Check unmatched strings, fix common ones
View(country_matches$unmatched)
# Check duplicates, and which regular expressions triggered them
View(country_matches$dup)
dt5newVars$coded_country <- country_matches$words
dt5newVars$coded_country[dt5newVars$coded_country %in% names(country_matches$unmatched)] <- NA


# CODE FOR EXPORT:
country_entry <- dt5newVars$country
country_names <- rnaturalearth::ne_countries(scale = "medium")$admin
# namTR <- paste0("data/cleaned data/countries ", format(Sys.time(), format = "%F %H-%M %Z"),".RData")
# save(country_entry, country_names, file = namTR)

rm(country_dict, country_matches)
```
<br>
<div class="alert alert-warning">
<strong><i class="fa fa-exclamation-triangle"></i> Action needed:</strong> <br> 
We currently have `r length(unique(dt5newVars$country))` different free text country responses. The most recent codes leaves `r sum(country_counts$n[country_counts$country != ""])` responses are still not consolidated.
</div>

### Visualize Response Rates (maybe moved somewhere else?)
We visualize how many responses we have per day.
```{r RespVis, echo=T, warning=F, message=F}
tmp <- setNames(data.frame(table(lubridate::round_date(dt5newVars$EndDate, unit = "12 hours"))),c("Date","Count"))
ggplot(tmp, aes(x=Date, y = Count))+
   geom_line(group = 1)+
   theme_bw()+
   # scale_y_continuous(limits = c(0, 158),
   #                    breaks = seq(0,160,20))+
   theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 8))
```


### Political Orientation   
Political orientation was measured per language. We merge these variables here.    
```{r PolOr, echo=T, warning=F, message=F}
# clean-up country coding:
rm(country_counts)

# political orientation
dt5newVars <- dt5newVars %>%
  mutate(PolOrX = labelled(rowSums(dplyr::select(., ends_with("_x")), na.rm = T), 
                           labels = NULL, label="Political Compass X-Coordinate"),
         PolOrY = labelled(rowSums(dplyr::select(., ends_with("_y")), na.rm = T), 
                           labels = NULL, label="Political Compass Y-Coordinate"),
         PolOrAuthoritarianLeft = rowSums(dplyr::select(., ends_with("_Authoritarian_Left")), na.rm = T),
         PolOrAuthoritarianLeftLab = dplyr::recode(PolOrAuthoritarianLeft, `1` =  "Authoritarian Left", `0` = ""),
         PolOrAuthoritarianRight = rowSums(dplyr::select(., ends_with("_Authoritarian_right")), na.rm = T),
         PolOrAuthoritarianRightLab = dplyr::recode(PolOrAuthoritarianRight, `1` =  "Authoritarian Right", `0` = ""),
         PolOrLibertarianLeft = rowSums(dplyr::select(., ends_with("_Libertarian_Left")), na.rm = T),
         PolOrLibertarianLeftLab = dplyr::recode(PolOrLibertarianLeft, `1` =  "Libertarian Left", `0` = ""),
         PolOrLibertarianRight = rowSums(dplyr::select(., ends_with("_Libertarian_Right")), na.rm = T),
         PolOrLibertarianRightLab = dplyr::recode(PolOrLibertarianRight, `1` =  "Libertarian Right", `0` = ""),
         PolOrOther = rowSums(dplyr::select(., ends_with("_Other")), na.rm = T),
         PolOrOtherLab = dplyr::recode(PolOrOther, `1` =  "Other", `0` = ""),
         PolOrCat = paste0(PolOrAuthoritarianLeftLab, 
                           PolOrAuthoritarianRightLab,
                           PolOrLibertarianLeftLab,
                           PolOrLibertarianRightLab,
                           PolOrOtherLab), 
         PolOrCat = as.factor(na_if(PolOrCat, ""))) %>%
  dplyr::select(-starts_with("Pol"),
         PolOrX,
         PolOrY,
         PolOrCat)
attr(dt5newVars$PolOrCat,'label') <- 'Political Orientation Quadrant'
```

### Affect    
<!-- TO DO: Write function for item analysis and scale construction -->


#### High Arousal Negative   
```{r affHighNeg, echo=T, results='asis', warning=F, message=F}
# High Arousal Negative
## Anger not measured in wave 1
#pairs.panels.new(dt5newVars %>% dplyr::select(affAnx, affNerv))

cat("<br>")

dt5newVars$affHighNeg.m <- scoreItems(keys=c(1,1), items = dt5newVars %>% dplyr::select(affAnx, affNerv), min = 1, max = 5)$scores

as.data.frame(psych::describe(dt5newVars$affHighNeg.m, skew=F)) %>%
  mutate(vars = "High Arousal Negative Affect") %>%
  kable(., caption = "High Arousal Negative Affect: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$affHighNeg.c <- scale(dt5newVars$affHighNeg.m, scale = F, center = T)
dt5newVars$affHighNeg.z <- scale(dt5newVars$affHighNeg.m, scale = T)
dt5newVars$affHighNeg.fa <- fa(dt5newVars %>% dplyr::select(affAnx, affNerv))$scores
```

#### Low Arousal Negative Affect  
```{r affLowNeg, echo=T, results='asis', warning=F, message=F}
# Low Arousal Negative Affect
ia.affLowNeg <- dt5newVars %>%
    dplyr::select(affBor, affExh, affDepr) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.affLowNeg$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.affLowNeg)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(affBor, affExh, affDepr))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Low Arousal Negative Affect: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(affBor, affExh, affDepr))

cat("<br>")

dt5newVars$affLowNeg.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(affBor, affExh, affDepr), min = 1, max = 5)$scores

as.data.frame(psych::describe(dt5newVars$affLowNeg.m, skew=F)) %>%
  mutate(vars = "Low Arousal Negative Affect") %>%
  kable(., caption = "Low Arousal Negative Affect: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$affLowNeg.c <- scale(dt5newVars$affLowNeg.m, scale = F, center = T)
dt5newVars$affLowNeg.z <- scale(dt5newVars$affLowNeg.m, scale = T)
dt5newVars$affLowNeg.fa <- fa(dt5newVars %>% dplyr::select(affBor, affExh, affDepr))$scores
```

#### Low Arousal Positive Affect  
```{r affLowPos, echo=T, results='asis', warning=F, message=F}
# Low Arousal Positive Affect
ia.affLowPos <- dt5newVars %>%
    dplyr::select(affCalm, affContent, affRel) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.affLowPos$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.affLowPos)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(affCalm, affContent, affRel))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Low Arousal Positive Affect: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(affCalm, affContent, affRel))

cat("<br>")

dt5newVars$affLowPos.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(affCalm, affContent, affRel), min = 1, max = 5)$scores

as.data.frame(psych::describe(dt5newVars$affLowPos.m, skew=F)) %>%
  mutate(vars = "Low Arousal Positive Affect") %>%
  kable(., caption = "Low Arousal Positive Affect: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$affLowPos.c <- scale(dt5newVars$affLowPos.m, scale = F, center = T)
dt5newVars$affLowPos.z <- scale(dt5newVars$affLowPos.m, scale = T)
dt5newVars$affLowPos.fa <- fa(dt5newVars %>% dplyr::select(affCalm, affContent, affRel))$scores
```

#### High Arousal Positive Affect  
```{r affHighPos, echo=T, results='asis', warning=F, message=F}
# High Arousal Positive Affect
ia.affHighPos <- dt5newVars %>%
    dplyr::select(affEnerg, affExc, affInsp) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.affHighPos$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.affHighPos)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(affEnerg, affExc, affInsp))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "High Arousal Positive Affect: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(affEnerg, affExc, affInsp))

cat("<br>")

dt5newVars$affHighPos.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(affEnerg, affExc, affInsp), min = 1, max = 5)$scores

as.data.frame(psych::describe(dt5newVars$affHighPos.m, skew=F)) %>%
  mutate(vars = "High Arousal Positive Affect") %>%
  kable(., caption = "High Arousal Positive Affect: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$affHighPos.c <- scale(dt5newVars$affHighPos.m, scale = F, center = T)
dt5newVars$affHighPos.z <- scale(dt5newVars$affHighPos.m, scale = T)
dt5newVars$affHighPos.fa <- fa(dt5newVars %>% dplyr::select(affEnerg, affExc, affInsp))$scores
```

### Loneliness
```{r lone, echo=T, results='asis', warning=F, message=F}
ia.lone<- dt5newVars %>%
    dplyr::select(starts_with("lone")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.lone$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.lone)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("lone")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Loneliness: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("lone")))

cat("<br>")

dt5newVars$lone.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(starts_with("lone")), min = 1, max = 5)$scores

as.data.frame(psych::describe(dt5newVars$lone.m, skew=F)) %>%
  mutate(vars = "Loneliness") %>%
  kable(., caption = "Loneliness: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$lone.c <- scale(dt5newVars$lone.m, scale = F, center = T)
dt5newVars$lone.z <- scale(dt5newVars$lone.m, scale = T)
dt5newVars$lone.fa <- fa(dt5newVars %>% dplyr::select(starts_with("lone")))$scores
```  

### Boredom
```{r bore, echo=T, results='asis', warning=F, message=F}
ia.bor<- dt5newVars %>%
    dplyr::select(starts_with("bor0"), -bor03) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.bor$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.bor)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("bor0"), -bor03))
```
<div class="alert alert-info">
<strong><i class="fa fa-exclamation-triangle"></i> Item dropped:</strong> <br> 
Item three was not well behaved. It seems to measure something else. We dropped it for now.
</div>

```{r bore.red, echo=T, results='asis', warning=F, message=F}

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("bor0"), -bor03, -bor03_R))

cat("<br>")

dt5newVars$bor.m <- scoreItems(keys=c(1,1), items = dt5newVars %>% dplyr::select(starts_with("bor0"), -bor03, -bor03_R), min = -3, max = 3)$scores

as.data.frame(psych::describe(dt5newVars$bor.m, skew=F)) %>%
  mutate(vars = "Boredom") %>%
  kable(., caption = "Boredom: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$bor.c <- scale(dt5newVars$bor.m, scale = F, center = T)
dt5newVars$bor.z <- scale(dt5newVars$bor.m, scale = T)
dt5newVars$bor.fa <- fa(dt5newVars %>% dplyr::select(starts_with("bor0"), -bor03, -bor03_R))$scores
```
  
### Isolation
```{r iso, echo=T, results='asis', warning=F, message=F}
cat(crayon::bold("Offline Isolation"))
ia.isoPers <- dt5newVars %>%
    dplyr::select(ends_with("inPerson"), -starts_with("w1_")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.isoPers$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.isoPers)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(ends_with("inPerson"), -starts_with("w1_")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Isolation offline: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(ends_with("inPerson"), -starts_with("w1_")))

cat("<br>")

dt5newVars$isoPers.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(ends_with("inPerson"), -starts_with("w1_")), min = 0, max = 7)$scores

as.data.frame(psych::describe(dt5newVars$isoPers.m, skew=F)) %>%
  mutate(vars = "Isolation offline") %>%
  kable(., caption = "Isolation offline: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$isoPers.c <- scale(dt5newVars$isoPers.m, scale = F, center = T)
dt5newVars$isoPers.z <- scale(dt5newVars$isoPers.m, scale = T)
dt5newVars$isoPers.fa <- fa(dt5newVars %>% dplyr::select(ends_with("inPerson"), -starts_with("w1_")))$scores

cat(crayon::bold("Online Isolation"))
ia.isoOnl <- dt5newVars %>%
    dplyr::select(ends_with("online"), -starts_with("w1_")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.isoOnl$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.isoOnl)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(ends_with("inPerson"), -starts_with("w1_")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Isolation online: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(ends_with("online"), -starts_with("w1_")))

cat("<br>")

dt5newVars$isoOnl.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(ends_with("online"), -starts_with("w1_")), min = 0, max = 7)$scores

as.data.frame(psych::describe(dt5newVars$isoPers.m, skew=F)) %>%
  mutate(vars = "Isolation online") %>%
  kable(., caption = "Isolation online: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$isoOnl.c <- scale(dt5newVars$isoOnl.m, scale = F, center = T)
dt5newVars$isoOnl.z <- scale(dt5newVars$isoOnl.m, scale = T)
dt5newVars$isoOnl.fa <- fa(dt5newVars %>% dplyr::select(ends_with("online"), -starts_with("w1_")))$scores

# Leave House
as.data.frame(psych::describe(dt5newVars$houseLeave, skew=F)) %>%
  mutate(vars = "Leaving House") %>%
  kable(., caption = "Leaving House: Item Descriptive", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")
```

### Government Clarity
```{r gov, echo=T, results='asis', warning=F, message=F}
as.data.frame(psych::describe(dt5newVars$extC19Msg)) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Government Response: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

ggplot(dt5newVars, aes(x = extC19Msg)) +
  geom_histogram(binwidth=1, alpha=0.5) +
  #geom_density(alpha=0.6)+
  labs(title="Government Response distribution",x="Government Response", y = "Frequency") +
  theme_Publication()
```

### Coronavirus Responses
#### Community Response
```{r community, echo=T, results='asis', warning=F, message=F}
ia.ext <- dt5newVars %>%
    dplyr::select(starts_with("extC19"), -extC19Msg) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.ext$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.ext)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("extC19"), -extC19Msg))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Community response: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("extC19"), -extC19Msg))

cat("<br>")

dt5newVars$ext.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(starts_with("extC19"), -extC19Msg), 
                             min = 1, max = 6)$scores

as.data.frame(psych::describe(dt5newVars$ext.m, skew=F)) %>%
  mutate(vars = "Community response") %>%
  kable(., caption = "Community response: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$ext.c <- scale(dt5newVars$ext.m, scale = F, center = T)
dt5newVars$ext.z <- scale(dt5newVars$ext.m, scale = T)
dt5newVars$ext.fa <- fa(dt5newVars %>% dplyr::select(starts_with("extC19"), -extC19Msg))$scores
```

#### Behavioral Response
```{r beh, echo=T, results='asis', warning=F, message=F}
ia.beh <- dt5newVars %>%
    dplyr::select(starts_with("c19per")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.beh$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.beh)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("c19per")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Behavioral response: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("c19per")))

cat("<br>")

dt5newVars$beh.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(starts_with("c19per")), 
                             min = -3, max = 3)$scores

as.data.frame(psych::describe(dt5newVars$beh.m, skew=F)) %>%
  mutate(vars = "Behavioral response") %>%
  kable(., caption = "Behavioral response: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$beh.c <- scale(dt5newVars$beh.m, scale = F, center = T)
dt5newVars$beh.z <- scale(dt5newVars$beh.m, scale = T)
dt5newVars$beh.fa <- fa(dt5newVars %>% dplyr::select(starts_with("c19per")))$scores
```

#### Pro-Social Response
```{r beh, echo=T, results='asis', warning=F, message=F}
ia.proSo <- dt5newVars %>%
    dplyr::select(starts_with("c19ProSo")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.proSo$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.proSo)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("c19ProSo")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Pro-Social response: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("c19ProSo")))

cat("<br>")

dt5newVars$proSo.m <- scoreItems(keys=c(1,1,1,1), items = dt5newVars %>% dplyr::select(starts_with("c19ProSo")), 
                             min = -3, max = 3)$scores

as.data.frame(psych::describe(dt5newVars$proSo.m, skew=F)) %>%
  mutate(vars = "Pro-Social response") %>%
  kable(., caption = "Pro-Social response: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$proSo.c <- scale(dt5newVars$proSo.m, scale = F, center = T)
dt5newVars$proSo.z <- scale(dt5newVars$proSo.m, scale = T)
dt5newVars$proSo.fa <- fa(dt5newVars %>% dplyr::select(starts_with("c19ProSo")))$scores
```

### Likelihood Threat
```{r likelihood, echo=T, results='asis', warning=F, message=F}
as.data.frame(psych::describe(dt5newVars$PLRAC19)) %>%
  mutate(vars = "Likelihood c19") %>%
  kable(., caption = "Likelihood c19: Item Descriptive", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

ggplot(dt5newVars, aes(x = PLRAC19)) +
  geom_histogram(binwidth=1, alpha=0.5) +
  #geom_density(alpha=0.6)+
  labs(title="Likelihood c19 distribution",x="Likelihood c19", y = "Frequency") +
  theme_Publication()
  
as.data.frame(psych::describe(dt5newVars$PLRAEco)) %>%
  mutate(vars = "Likelihood Eco") %>%
  kable(., caption = "Likelihood Eco: Item Descriptive", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

ggplot(dt5newVars, aes(x = PLRAEco)) +
  geom_histogram(binwidth=1, alpha=0.5) +
  #geom_density(alpha=0.6)+
  labs(title="Likelihood Eco distribution",x="Likelihood Eco", y = "Frequency") +
  theme_Publication()
```

### Hope and Efficacy
```{r hopeEff, echo=T, results='asis', warning=F, message=F}
as.data.frame(psych::describe(dt5newVars$c19Hope)) %>%
  mutate(vars = "Hope") %>%
  kable(., caption = "Hope: Item Descriptive", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

ggplot(dt5newVars, aes(x = c19Hope)) +
  geom_histogram(binwidth=1, alpha=0.5) +
  #geom_density(alpha=0.6)+
  labs(title="Hope distribution",x="Corona Virus Hope", y = "Frequency") +
  theme_Publication()
  
as.data.frame(psych::describe(dt5newVars$c19Eff)) %>%
  mutate(vars = "Efficacy") %>%
  kable(., caption = "Efficacy: Item Descriptive", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

ggplot(dt5newVars, aes(x = c19Eff)) +
  geom_histogram(binwidth=1, alpha=0.5) +
  #geom_density(alpha=0.6)+
  labs(title="Efficacy distribution",x="Corona Virus Efficacy", y = "Frequency") +
  theme_Publication()
```

### State Paranoia
```{r para, echo=T, results='asis', warning=F, message=F}
ia.para <- dt5newVars %>%
    dplyr::select(starts_with("para")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.para$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.para)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("para")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "State Paranoia: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("para")))

cat("<br>")

dt5newVars$para.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(starts_with("para")), 
                             min = 0, max = 10)$scores

as.data.frame(psych::describe(dt5newVars$para.m, skew=F)) %>%
  mutate(vars = "State Paranoia") %>%
  kable(., caption = "State Paranoia: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$para.c <- scale(dt5newVars$para.m, scale = F, center = T)
dt5newVars$para.z <- scale(dt5newVars$para.m, scale = T)
dt5newVars$para.fa <- fa(dt5newVars %>% dplyr::select(starts_with("para")))$scores
```

### Conspiracy Theory
```{r consp, echo=T, results='asis', warning=F, message=F}
ia.consp <- dt5newVars %>%
    dplyr::select(starts_with("consp")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.consp$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.consp)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("consp")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Conspiracy Theory: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("consp")))

cat("<br>")

dt5newVars$consp.m <- scoreItems(keys=c(1,1,1), items = dt5newVars %>% dplyr::select(starts_with("consp")), 
                             min = 0, max = 10)$scores

as.data.frame(psych::describe(dt5newVars$consp.m, skew=F)) %>%
  mutate(vars = "Conspiracy Theory") %>%
  kable(., caption = "Conspiracy Theory: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$para.c <- scale(dt5newVars$consp.m, scale = F, center = T)
dt5newVars$para.z <- scale(dt5newVars$consp.m, scale = T)
dt5newVars$para.fa <- fa(dt5newVars %>% dplyr::select(starts_with("consp")))$scores
```

### Disempowerment
```{r disemp, echo=T, results='asis', warning=F, message=F}
ia.disemp<- dt5newVars %>%
    dplyr::select(starts_with("fail"), -contains("DO")) %>%
    na_if(., -99) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.disemp$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.disemp)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("fail"), -contains("DO")) %>% na_if(., -99))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Disempowerment: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("fail"), -contains("DO")) %>% na_if(., -99))

cat("<br>")

dt5newVars$disemp.m <- scoreItems(keys=c(1,1,1), 
                                  items = dt5newVars %>% dplyr::select(starts_with("fail"), -contains("DO")) %>% na_if(., -99),
                                  min = -2, max = 2)$scores

as.data.frame(psych::describe(dt5newVars$disemp.m, skew=F)) %>%
  mutate(vars = "Disempowerment") %>%
  kable(., caption = "Disempowerment: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$disemp.c <- scale(dt5newVars$disemp.m, scale = F, center = T)
dt5newVars$disemp.z <- scale(dt5newVars$disemp.m, scale = T)
dt5newVars$disemp.fa <- fa(dt5newVars %>% dplyr::select(starts_with("fail"), -contains("DO")))$scores
```

### Societal Discontent
```{r socDis, echo=T, results='asis', warning=F, message=F}
ia.socdisc<- dt5newVars %>%
    dplyr::select(starts_with("disc"), -discPers , -disc03, -contains("DO")) %>%
    na_if(., -99) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.socdisc$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.socdisc)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("disc"), -discPers , -disc03, -contains("DO")) %>% na_if(., -99))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Societal Discontent: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("disc"), -discPers , -disc03, -contains("DO")) %>% na_if(., -99))

cat("<br>")

dt5newVars$socdisc.m <- scoreItems(keys=c(1,1,1), 
                                  items = dt5newVars %>% dplyr::select(starts_with("disc"), -discPers , -disc03, -contains("DO")) %>% na_if(., -99),
                                  min = -2, max = 2)$scores

as.data.frame(psych::describe(dt5newVars$socdisc.m, skew=F)) %>%
  mutate(vars = "Societal Discontent") %>%
  kable(., caption = "Societal Discontent: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$socdisc.c <- scale(dt5newVars$socdisc.m, scale = F, center = T)
dt5newVars$socdisc.z <- scale(dt5newVars$socdisc.m, scale = T)
dt5newVars$socdisc.fa <- fa(dt5newVars %>% dplyr::select(starts_with("disc"), -discPers , -disc03, -contains("DO")))$scores
```

### Job Insecurity
```{r jbinsc, echo=T, results='asis', warning=F, message=F}
ia.jobinsec<- dt5newVars %>%
    dplyr::select(starts_with("jbInsec"), -jbInsec02, -jbInsec04) %>%
    na_if(., -99) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.jobinsec$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.jobinsec)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("jbInsec"), -jbInsec02, -jbInsec04) %>% na_if(., -99))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Job insecurity: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("jbInsec"), -jbInsec02, -jbInsec04) %>% na_if(., -99))

cat("<br>")

dt5newVars$jobinsec.m <- scoreItems(keys=c(1,1,1), 
                                  items = dt5newVars %>% dplyr::select(starts_with("jbInsec"), -jbInsec02, -jbInsec04) %>% na_if(., -99),
                                  min = -2, max = 2)$scores

as.data.frame(psych::describe(dt5newVars$jobinsec.m, skew=F)) %>%
  mutate(vars = "Job insecurity") %>%
  kable(., caption = "Job insecurity: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$jobinsec.c <- scale(dt5newVars$jobinsec.m, scale = F, center = T)
dt5newVars$jobinsec.z <- scale(dt5newVars$jobinsec.m, scale = T)
dt5newVars$jobinsec.fa <- fa(dt5newVars %>% dplyr::select(starts_with("jbInsec"), -jbInsec02, -jbInsec04))$scores
```

### Financial Strain
```{r finance, echo=T, results='asis', warning=F, message=F}
ia.pfs<- dt5newVars %>%
    dplyr::select(starts_with("PFS0")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.pfs$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.pfs)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("PFS0")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Financial Strain: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("PFS0")))

cat("<br>")

dt5newVars$pfs.m <- scoreItems(keys=c(1,1,1), 
                                  items = dt5newVars %>% dplyr::select(starts_with("PFS0")),
                                  min = -2, max = 2)$scores

as.data.frame(psych::describe(dt5newVars$pfs.m, skew=F)) %>%
  mutate(vars = "Financial Strain") %>%
  kable(., caption = "Financial Strain: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$pfs.c <- scale(dt5newVars$pfs.m, scale = F, center = T)
dt5newVars$pfs.z <- scale(dt5newVars$pfs.m, scale = T)
dt5newVars$pfs.fa <- fa(dt5newVars %>% dplyr::select(starts_with("PFS0")))$scores
```

### Coping
#### Problem Solving
```{r probSolv, echo=T, results='asis', warning=F, message=F}
ia.probSolv<- dt5newVars %>%
    dplyr::select(starts_with("probSolving"), -contains("DO")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.probSolv$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.probSolv)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("probSolving"), -contains("DO")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Problem Solving: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("probSolving"), -contains("DO")))

cat("<br>")

dt5newVars$probSolv.m <- scoreItems(keys=c(1,1,1), 
                                  items = dt5newVars %>% dplyr::select(starts_with("probSolving"), -contains("DO")),
                                  min = -2, max = 2)$scores

as.data.frame(psych::describe(dt5newVars$probSolv.m, skew=F)) %>%
  mutate(vars = "Problem Solving") %>%
  kable(., caption = "Problem Solving: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$probSolv.c <- scale(dt5newVars$probSolv.m, scale = F, center = T)
dt5newVars$probSolv.z <- scale(dt5newVars$probSolv.m, scale = T)
dt5newVars$probSolv.fa <- fa(dt5newVars %>% dplyr::select(starts_with("probSolving"), -contains("DO")))$scores
```

#### Distraction
```{r distract, echo=T, results='asis', warning=F, message=F}
ia.distract<- dt5newVars %>%
    dplyr::select(starts_with("posrefocus"), -contains("DO")) %>%
    Scale::Scale() %>%
    Scale::ItemAnalysis()
ia.distract$rely   
cat("<br><br>A gls factor analysis was conducted. Items were regressed to a single factor. Their loadings are the following:")
as.data.frame(Scale::ReportTable(ia.distract)) %>%
  kable(., row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

as.data.frame(psych::describe(dt5newVars %>% dplyr::select(starts_with("posrefocus"), -contains("DO")))) %>%
  mutate(vars = rownames(.)) %>%
  kable(., caption = "Distraction: Item Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

cat("<br>")

#pairs.panels.new(dt5newVars %>% dplyr::select(starts_with("posrefocus"), -contains("DO")))

cat("<br>")

dt5newVars$distract.m <- scoreItems(keys=c(1,1,1), 
                                  items = dt5newVars %>% dplyr::select(starts_with("posrefocus"), -contains("DO")),
                                  min = -2, max = 2)$scores

as.data.frame(psych::describe(dt5newVars$distract.m, skew=F)) %>%
  mutate(vars = "Distraction") %>%
  kable(., caption = "Distraction: Scale Descriptives", row.names = FALSE) %>% 
  kable_styling("hover", full_width = F, latex_options = "hold_position")

dt5newVars$distract.c <- scale(dt5newVars$distract.m, scale = F, center = T)
dt5newVars$distract.z <- scale(dt5newVars$distract.m, scale = T)
dt5newVars$distract.fa <- fa(dt5newVars %>% dplyr::select(starts_with("posrefocus"), -contains("DO")))$scores
```

## **Reduce to Relevant Variales**   
```{r keyVars, echo=T, warning=F, message=F}
# clean-up Item Analyses
rm(list=ls(pattern="ia"))

# remove directly identifiable data (with and without page timers)
dt6ReducedTimer <- dt5newVars %>%
  dplyr::select(-c(contains("IPAddress"),
                   contains("RecipientLastName"), 
                   contains("RecipientFirstName"), 
                   contains("Email"),
                   contains("ExternalReference"), 
                   contains("LocationLatitude"), 
                   contains("LocationLongitude"),
                   contains("DistributionChannel"),
                   contains("ICRec_0_TEXT"),
                   contains("ICRec_1_TEXT")))
dt6Reduced <- dt6ReducedTimer %>%
  dplyr::select(-starts_with("t_"))

# # remove filtered cases (with and without page timers)
# dt6ReducedTimerCases <- dt6ReducedTimer %>%
#   filter(FilterPreview == 0,
#          FilterProgress == 0,
#          FilterTime == 0,
#          FilterStraightliner == 0) %>%
#   dplyr::select(-starts_with("Filter"))
# dt6ReducedCases <- dt6Reduced %>%
#   filter(FilterPreview == 0,
#          FilterProgress == 0,
#          FilterTime == 0,
#          FilterStraightliner == 0) %>%
#   dplyr::select(-starts_with("Filter"))
```

## **Recontact**
```{r recontact, echo=T, warning=F, message=F}
# COMMENT IF NEEDED
# as.Date(dt5newVars$EndDate) 
# 
# library("lubridate")
# ContactList1 <- dt5newVars %>%
#   filter(FilterPreview == 0,
#          ICRec_1_TEXT!="",
#          ymd_hms(dt5newVars$EndDate) < "2020-04-07 12:00:00 UTC") %>% #change in larger next wave
#   dplyr::distinct(ICRec_1_TEXT, .keep_all = TRUE) %>%
#   dplyr::select(ExternalDataReference = ResponseId, 
#                 Language = Q_Language, 
#                 Email = ICRec_1_TEXT,
#                 StartDateBaseline = StartDate, 
#                 EndDateBaseline = EndDate)
# 
# table(ContactList1$Language)
# 
# # check how many have an @ (not really worth the effort to discard those)
#   table(ifelse(grepl("@", ContactList1$Email), "keep", "discard"))
# 
# n_occur <- data.frame(table(ContactList1$ExternalDataReference)) #data frame with  list of ids and number of times they occurred
# n_occur[n_occur$Freq > 1,] #which ids occurred more than once.
# ContactList1[ContactList1$ExternalDataReference %in% n_occur$Var1[n_occur$Freq > 1],] #which ones
# 
# write.csv(ContactList1,'data/cleaned data/2020_04_10_ContactList.csv')
# 
# #LanguageList <- as.data.frame(sort(table(dt6ReducedCases$language), decreasing = T))
```

## **Data for Shiny App**
```{r shiny, echo=T, warning=F, message=F}
# Dataframe for Shiny App
# load geo spatial data
library(rnaturalearth)
library(rnaturalearthdata)
world.data <- ne_countries(scale = "medium", returnclass = "sf")
unique(dt5newVars$coded_country)[!unique(dt5newVars$coded_country) %in% world.data$admin] # check whether all country names are spelled correctly

# all ISO-2 country code to dataframe and flags
shiny_prep <- merge(x = dt5newVars, y = world.data %>% dplyr::select(admin, iso_a2), by.x = "coded_country", by.y = "admin", all.x = T)
shiny_prep$flag <- sprintf("https://cdn.rawgit.com/lipis/flag-icon-css/master/flags/4x3/%s.svg", tolower(shiny_prep$iso_a2))

ctry.scales <- shiny_prep %>%
  filter(!is.na(coded_country)) %>%
  dplyr::group_by(coded_country) %>%
  dplyr::summarize(
    n = n()+sample(-5:5, 1, replace=TRUE),
    
    affAnx = mean(affAnx, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affBor = mean(affBor, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affCalm = mean(affCalm, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affContent = mean(affContent, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affDepr = mean(affDepr, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affEnerg = mean(affEnerg, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affExc = mean(affExc, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affNerv = mean(affNerv, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affExh = mean(affExh, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affInsp = mean(affInsp, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affRel = mean(affRel, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affHighPos = mean(affHighPos.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affHighNeg = mean(affHighNeg.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affLowPos = mean(affLowPos.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affLowNeg = mean(affLowNeg.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    
    #ext = mean(ext.m, na.rm = T),
    
    gov = mean(extC19Msg, na.rm = T)+rnorm(1, mean=0, sd=.2),
    gov.sd = sd(extC19Msg, na.rm = T),
    gov.se = gov.sd/sqrt(n),
    
    comRule = mean(extC19Rules, na.rm = T)+rnorm(1, mean=0, sd=.2),
    comRule.sd = sd(extC19Rules, na.rm = T),
    comRule.se = comRule.sd/sqrt(n),
    
    comPunish = mean(extC19Punish, na.rm = T)+rnorm(1, mean=0, sd=.2),
    comPunish.sd = sd(extC19Punish, na.rm = T),
    comPunish.se = comPunish.sd/sqrt(n),
    
    comOrg = mean(extC19Org, na.rm = T)+rnorm(1, mean=0, sd=.2),
    comOrg.sd = sd(extC19Org, na.rm = T),
    comOrg.se = comOrg.sd/sqrt(n),
    
    lone = mean(lone.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    lone.sd = sd(lone.m, na.rm = T),
    lone.se = lone.sd/sqrt(n),
    
    #bor = mean(bor.m, na.rm = T),
    isoPers = mean(isoPers.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    isoPers.sd = sd(isoPers.m, na.rm = T),
    isoPers.se = isoPers.sd/sqrt(n),
    
    isoOnl = mean(isoOnl.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    isoOnl.sd = sd(isoOnl.m, na.rm = T),
    isoOnl.se = isoOnl.sd/sqrt(n),
    
    #beh = mean(beh.m, na.rm = T),
    behWash = mean(c19perBeh01, na.rm = T)+rnorm(1, mean=0, sd=.2),
    behWash.sd = sd(c19perBeh01, na.rm = T),
    behWash.se = behWash.sd/sqrt(n),
    
    behAvoid = mean(c19perBeh02, na.rm = T)+rnorm(1, mean=0, sd=.2),
    behAvoid.sd = sd(c19perBeh02, na.rm = T),
    behAvoid.se = behAvoid.sd/sqrt(n),
    
    covidHope = mean(c19Hope, na.rm = T)+rnorm(1, mean=0, sd=.2),
    covidHope.sd = sd(c19Hope, na.rm = T),
    covidHope.se = covidHope.sd/sqrt(n),
    
    covidEff = mean(c19Eff, na.rm = T)+rnorm(1, mean=0, sd=.2),
    covidEff.sd = sd(c19Eff, na.rm = T),
    covidEff.se = covidEff.sd/sqrt(n),
    
    para = mean(para.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    para.sd = sd(para.m, na.rm = T),
    para.se = para.sd/sqrt(n),
    
    consp = mean(consp.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    consp.sd = sd(consp.m, na.rm = T),
    consp.se = consp.sd/sqrt(n)
    
    #jobinsec = mean(jobinsec.m, na.rm = T),
    #pfs = mean(pfs.m, na.rm = T),
  )
ctry.scales <- merge(x = ctry.scales, y = unique(shiny_prep %>% dplyr::select(coded_country, iso_a2, flag)), all.x = T) # add flags and ISO

global.scales <- shiny_prep %>%
  filter(!is.na(coded_country)) %>%
  dplyr::summarize(
    coded_country = "global",
    n = n()+sample(-5:5, 1, replace=TRUE),
    
    affAnx = mean(affAnx, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affBor = mean(affBor, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affCalm = mean(affCalm, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affContent = mean(affContent, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affDepr = mean(affDepr, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affEnerg = mean(affEnerg, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affExc = mean(affExc, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affNerv = mean(affNerv, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affExh = mean(affExh, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affInsp = mean(affInsp, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affRel = mean(affRel, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affHighPos = mean(affHighPos.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affHighNeg = mean(affHighNeg.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affLowPos = mean(affLowPos.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    affLowNeg = mean(affLowNeg.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    
    #ext = mean(ext.m, na.rm = T),
    
    gov = mean(extC19Msg, na.rm = T)+rnorm(1, mean=0, sd=.2),
    gov.sd = sd(extC19Msg, na.rm = T),
    gov.se = gov.sd/sqrt(n),
    
    comRule = mean(extC19Rules, na.rm = T)+rnorm(1, mean=0, sd=.2),
    comRule.sd = sd(extC19Rules, na.rm = T),
    comRule.se = comRule.sd/sqrt(n),
    
    comPunish = mean(extC19Punish, na.rm = T)+rnorm(1, mean=0, sd=.2),
    comPunish.sd = sd(extC19Punish, na.rm = T),
    comPunish.se = comPunish.sd/sqrt(n),
    
    comOrg = mean(extC19Org, na.rm = T)+rnorm(1, mean=0, sd=.2),
    comOrg.sd = sd(extC19Org, na.rm = T),
    comOrg.se = comOrg.sd/sqrt(n),
    
    lone = mean(lone.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    lone.sd = sd(lone.m, na.rm = T),
    lone.se = lone.sd/sqrt(n),
    
    #bor = mean(bor.m, na.rm = T),
    isoPers = mean(isoPers.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    isoPers.sd = sd(isoPers.m, na.rm = T),
    isoPers.se = isoPers.sd/sqrt(n),
    
    isoOnl = mean(isoOnl.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    isoOnl.sd = sd(isoOnl.m, na.rm = T),
    isoOnl.se = isoOnl.sd/sqrt(n),
    
    #beh = mean(beh.m, na.rm = T),
    behWash = mean(c19perBeh01, na.rm = T)+rnorm(1, mean=0, sd=.2),
    behWash.sd = sd(c19perBeh01, na.rm = T),
    behWash.se = behWash.sd/sqrt(n),
    
    behAvoid = mean(c19perBeh02, na.rm = T)+rnorm(1, mean=0, sd=.2),
    behAvoid.sd = sd(c19perBeh02, na.rm = T),
    behAvoid.se = behAvoid.sd/sqrt(n),
    
    covidHope = mean(c19Hope, na.rm = T)+rnorm(1, mean=0, sd=.2),
    covidHope.sd = sd(c19Hope, na.rm = T),
    covidHope.se = covidHope.sd/sqrt(n),
    
    covidEff = mean(c19Eff, na.rm = T)+rnorm(1, mean=0, sd=.2),
    covidEff.sd = sd(c19Eff, na.rm = T),
    covidEff.se = covidEff.sd/sqrt(n),
    
    para = mean(para.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    para.sd = sd(para.m, na.rm = T),
    para.se = para.sd/sqrt(n),
    
    consp = mean(consp.m, na.rm = T)+rnorm(1, mean=0, sd=.2),
    consp.sd = sd(consp.m, na.rm = T),
    consp.se = consp.sd/sqrt(n),
    
    #jobinsec = mean(jobinsec.m, na.rm = T),
    #pfs = mean(pfs.m, na.rm = T),
    #jobinsec = mean(jobinsec.m, na.rm = T),
    #pfs = mean(pfs.m, na.rm = T),
    iso_a2 = NA,
    flag = "https://rawcdn.githack.com/FortAwesome/Font-Awesome/4e6402443679e0a9d12c7401ac8783ef4646657f/svgs/solid/globe.svg"
  )
ctry.scales <- rbind(global.scales, ctry.scales); rm(global.scales)

languages <- shiny_prep %>% 
  dplyr::select(coded_country, language) %>%
  group_by(language, coded_country) %>%
  tally() %>%
  tidyr::spread(language, n)
languages.glob <- shiny_prep %>%
  dplyr::select(language) %>%
  mutate(coded_country = "global") %>%
  group_by(language, coded_country) %>%
  tally() %>%
  tidyr::spread(language, n)
languages <- rbind(languages.glob, languages); rm(languages.glob)
names(languages)[names(languages) != "coded_country"] = paste0("languages_", names(languages)[names(languages) != "coded_country"])

gender <- data.frame(coded_country = shiny_prep$coded_country, 
                     gender = as_factor(shiny_prep$gender)) %>%
  group_by(gender, coded_country) %>%
  tally() %>%
  tidyr::spread(gender, n)
gender.glob <- data.frame(coded_country = "global", 
                             gender = as_factor(shiny_prep$gender)) %>%
  group_by(gender, coded_country) %>%
  tally() %>%
  tidyr::spread(gender, n)
gender <- rbind(gender.glob, gender); rm(gender.glob)
names(gender)[names(gender) != "coded_country"] = paste0("gender_", names(gender)[names(gender) != "coded_country"])

age <- data.frame(coded_country = shiny_prep$coded_country, 
                  age = as_factor(shiny_prep$age)) %>%
  group_by(age, coded_country) %>%
  tally() %>%
  tidyr::spread(age, n)
age.glob <- data.frame(coded_country = "global",
                       age = as_factor(shiny_prep$age)) %>%
  group_by(age, coded_country) %>%
  tally() %>%
  tidyr::spread(age, n)
age <- rbind(age.glob, age); rm(age.glob)
names(age)[names(age) != "coded_country"] = paste0("age_", names(age)[names(age) != "coded_country"])

edu <- data.frame(coded_country = shiny_prep$coded_country, 
                  edu = as_factor(shiny_prep$edu)) %>%
  group_by(edu, coded_country) %>%
  tally() %>%
  tidyr::spread(edu, n)
edu.glob <- data.frame(coded_country = "global", 
                       edu = as_factor(shiny_prep$edu)) %>%
  group_by(edu, coded_country) %>%
  tally() %>%
  tidyr::spread(edu, n)
edu <- rbind(edu.glob, edu); rm(edu.glob)
names(edu)[names(edu) != "coded_country"] = paste0("education_", names(edu)[names(edu) != "coded_country"])

pol <- shiny_prep %>%
  dplyr::select(coded_country, PolOrCat) %>%
  mutate(PolOrCat = na_if(PolOrCat, "Libertarian LeftLibertarian Right")) %>%
  mutate(PolOrCat = na_if(PolOrCat, "Authoritarian RightLibertarian Right")) %>%
  group_by(PolOrCat, coded_country) %>%
  tally() %>%
  tidyr::spread(PolOrCat, n)
pol.glob <- shiny_prep %>%
  dplyr::select(PolOrCat) %>%
  mutate(PolOrCat = na_if(PolOrCat, "Libertarian LeftLibertarian Right")) %>%
  mutate(PolOrCat = na_if(PolOrCat, "Authoritarian RightLibertarian Right")) %>%
  mutate(coded_country = "global") %>%
  group_by(PolOrCat, coded_country) %>%
  tally() %>%
  tidyr::spread(PolOrCat, n)
pol <- rbind(pol.glob, pol); rm(pol.glob)
names(pol)[names(pol) != "coded_country"] = paste0("political_", names(pol)[names(pol) != "coded_country"])

#ctry.scales <- merge(x=ctry.scales, y=languages, by="coded_country", all.x=TRUE)
ctry.scales <- plyr::join(x=ctry.scales, y=languages, by="coded_country")
ctry.scales <- plyr::join(x=ctry.scales, y=gender, by="coded_country")
ctry.scales <- plyr::join(x=ctry.scales, y=age, by="coded_country")
ctry.scales <- plyr::join(x=ctry.scales, y=edu, by="coded_country")
ctry.scales <- plyr::join(x=ctry.scales, y=pol, by="coded_country")
rm(languages, gender, age, edu, pol)

# sample size per country (including NA)
world.n <- shiny_prep %>% 
  dplyr::select(coded_country, iso_a2, flag) %>%
  dplyr::group_by(coded_country, iso_a2, flag) %>%
  dplyr::summarize(
    n = n()+sample(-5:5, 1, replace=TRUE)
  )

ctry.red <- ctry.scales %>%
  dplyr::select(coded_country, iso_a2, flag, n) %>%
  filter(n >= 20) #, coded_country != "global"
ctry.only.red <- ctry.scales %>%
  dplyr::select(coded_country, iso_a2, flag, n) %>%
  filter(n >= 20, coded_country != "global")
```

## **Descriptives for Representativeness**
```{r rep, echo=T, warning=F, message=F}
# missing filter per item
  ctry.repMiss <- dt5newVars %>%
    #filter(!is.na(coded_country)) %>%
    filter(!is.na(PLRAC19),
           !is.na(extC19Msg),
           !is.na(pfs.m),
           !is.na(consp.m),
           !is.na(lone.m)
           ) %>%
    filter_at(vars(jbInsec01,jbInsec02, jbInsec03, jbInsec04, PLRAEco),all_vars(!is.na(.))) %>%
    filter_at(vars(disc01,disc02, disc03),all_vars(!is.na(.))) %>%
    filter_at(vars(isoFriends_inPerson, isoOthPpl_inPerson, isoFriends_online, isoOthPpl_online),all_vars(!is.na(.))) %>%
    filter_at(vars(c19Hope, c19Eff, ecoHope, ecoEff),all_vars(!is.na(.))) %>%
    filter_at(vars(c19RCA01, c19RCA02, c19RCA03, ecoPerBeh01, ecoPerBeh02, ecoPerBeh03),all_vars(!is.na(.))) %>%
    filter_at(vars(c19NormShould, c19ProSo01, c19ProSo02, c19ProSo03),all_vars(!is.na(.))) %>%
    filter_at(vars(c19NormDo, extC19Rules, extC19Punish, extC19Org),all_vars(!is.na(.))) %>%
    filter_at(vars(c19ProSo01, c19ProSo02, c19ProSo03, c19ProSo04, ecoProSo01, ecoProSo02, ecoProSo03, ecoProSo04),all_vars(!is.na(.))) %>%
    group_by(coded_country) %>%
    dplyr::summarize(
      n = n(),
      gender_women = sum(gender == 1, na.rm = T),
      gender_men = sum(gender == 2, na.rm = T),
      gender_other = sum(gender == 3, na.rm = T),
      gender_na = sum(is.na(gender), na.rm = T),
      age_18to24 = sum(age == 1, na.rm = T),
      age_25to34 = sum(age == 2, na.rm = T),
      age_35to44 = sum(age == 3, na.rm = T),
      age_45to54 = sum(age == 4, na.rm = T),
      age_55to64 = sum(age == 5, na.rm = T),
      age_65to75 = sum(age == 6, na.rm = T),
      age_75to85 = sum(age == 7, na.rm = T),
      age_85plus = sum(age == 8, na.rm = T),
      age_na = sum(is.na(age), na.rm = T)
    )
# no missing filter per item
  ctry.repFull <- dt5newVars %>%
    group_by(coded_country) %>%
    dplyr::summarize(
      n = n(),
      gender_women = sum(gender == 1, na.rm = T),
      gender_men = sum(gender == 2, na.rm = T),
      gender_other = sum(gender == 3, na.rm = T),
      gender_na = sum(is.na(gender), na.rm = T),
      age_18to24 = sum(age == 1, na.rm = T),
      age_25to34 = sum(age == 2, na.rm = T),
      age_35to44 = sum(age == 3, na.rm = T),
      age_45to54 = sum(age == 4, na.rm = T),
      age_55to64 = sum(age == 5, na.rm = T),
      age_65to75 = sum(age == 6, na.rm = T),
      age_75to85 = sum(age == 7, na.rm = T),
      age_85plus = sum(age == 8, na.rm = T),
      age_na = sum(is.na(age), na.rm = T)
    )
  ctry.repFull <- ctry.repFull %>%
    filter(n > 20)%>%
    transmute(coded_country = coded_country,
           n = n)
# language
  lang.repFull <- dt5newVars %>%
    group_by(language) %>%
    dplyr::summarize(
      n = n())
  lang.repFull <- lang.repFull %>%
    filter(n > 20)
```

## **Export**   
Export main dataframe as RData and SPSS sav files. We export versions with and without page timers
```{r export, echo=T, warning=F, message=F}
namSPSS <- paste0("data/cleaned data/Psycorona Baseline cleaned ", format(Sys.time(), format = "%F %H-%M %Z"),".sav")
namR <- paste0("data/cleaned data/Psycorona Baseline cleaned ", format(Sys.time(), format = "%F %H-%M %Z"),".RData")
namTSPSS <- paste0("data/cleaned data/Psycorona Baseline cleaned with page timer ", format(Sys.time(), format = "%F %H-%M %Z"),".sav")
namTR <- paste0("data/cleaned data/Psycorona Baseline cleaned with page timer ", format(Sys.time(), format = "%F %H-%M %Z"),".RData")
namCL <- paste0("data/cleaned data/Contact List ", format(Sys.time(), format = "%F %H-%M %Z"),".csv")
namLL <- paste0("data/cleaned data/Language List ", format(Sys.time(), format = "%F %H-%M %Z"),".csv")
namDemo <- paste0("data/cleaned data/Country Demographics ", format(Sys.time(), format = "%F %H-%M %Z"),".csv")

write_sav(dt6Reduced, namSPSS)
write_sav(dt6ReducedTimer, namTSPSS)

save(dt6Reduced, file = namR)
save(dt6ReducedTimer, file = namTR)

# export for Shiny
save(ctry.scales, world.n, ctry.red, ctry.only.red, file = "../PsyCorona-WebApp/data/shinyDataAggregated.RData")

# export Contact List
#write.csv(ContactList, file = namCL)

# export Language List
#write.csv(LanguageList, file = namLL)

# export Country Demographics

  #write.csv(ctry.repMiss,'data/cleaned data/Country Demographics Joce.csv')
  write.csv(ctry.repFull,'data/cleaned data/Country Size Full.csv')
  write.csv(lang.repFull,'data/cleaned data/Language.csv')

rm(list=ls(pattern="nam"))
```
